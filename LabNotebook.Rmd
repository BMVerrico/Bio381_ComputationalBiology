---
output: 
  html_document: 
    number_sections: yes
---
# 2018 BIO381 Notebook

### Author: BMVerrico
### Affiliation: Plant Biology Department, University of Vermont   
### Contact: bverrico@uvm.edu

### Date started: 2018-01-16    
### Date end (last modified):   


**Introduction:**    
Lecture and lab notes for BIOL381 Computational Biology. Not very detailed or descriptive, but little tid bits to help in the future.

<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.  

### Notes (day of lecture/lab)       
* [Page 1: 2018-01-16](#id-section1). 
* [Page 2: 2018-01-17](#id-section2).
* [Page 3: 2018-01-18](#id-section3). 
* [Page 4: 2018-01-23](#id-section4). 
* [Page 5: 2018-01-24](#id-section5). 
* [Page 6: 2018-01-25](#id-section6) 
* [Page 7: 2018-01-30](#id-section7). 
* [Page 8: 2018-01-31](#id-section8). 
* [Page 9: 2018-02-01](#id-section9).
* [Page 10: 2018-02-06](#id-section10).
* [Page 11: 2018-02-07](#id-section11).
* [Page 12: 2018-02-08](#id-section12).
* [Page 13: 2018-02-13](#id-section13).
* [Page 14: 2018-02-14](#id-section14).
* [Page 15: 2018-02-15](#id-section15).
* [Page 16: 2018-02-20](#id-section16).
* [Page 17: 2018-02-22](#id-section17).
* [Page 18: 2018-02-27](#id-section18).
* [Page 19: 2018-02-28](#id-section19).

------

<div id='id-section1'/>
## Page 1: 16 Jan 2018 

1. how to think on paper
2. how to use modern computational tools for science 
3. foundational methods in computer programming (also can be applied to perl, java, C++)
4. experimental design
5. publication quality graphics in R
6. students teach R package
7. probability distributions to simulate data

**GitHub**

* point of it is version control = systematically organize different versions of document
* git = version control software
* GitHub = free remove public website where project is stored (hosts git software)
* good with multiple authors on a document
* cloning: create a local copy of your repository, which is made up of files (any document)
and what git creates to keep track of your files that you are working on
* $6/month -- private repository 
* commit = set of recorded changes to the repostory (snapshot of data and datafiles)
* commit = to create a commit and description of it

```{}
Example:

---------> TIME
A A'
B B
C delete C
* D
  ~
  
* COMMIT WITH JUST ABC
~ COMMIT WITH A' B delete C and creation of D
(each time something is changed, add a new commit (with a unique id) with brief description

-o-o-o-o-o master branch of commits
		\ (fork)
		o-o-o-o-o (last o= head of branch)
```

* git keeps track of only the changes and then reconstructs previous versions of the files
* if a mistake is made, then you return the system back to the previous commit
* can create fork and then go on another path

* do work. make commit. push changes to GitHub, which updates repository online
* pull latest version of repository from GitHub
* GitHub desktop has synchronize which pushes and pulls, also updates webpage 
* ng only looks at webpage not repository 
* index page is the main core page for the webpage, can link off of that though
* no one can change webpage unless listed on GitHub
* each repo can have it's own webpage/portfolio

* no uncommitted changes means the local version and github version are synched and up to date
* ng hits sync just to make sure

* you are always working on the local respo. 
* commit to master is local, it does not sync to online
* sync is needed to push to GitHub site.

* GitHub only cares about files. not the folders/directory. the directory is needed to 
locate the file, but that is all.
* if you have a directory without a file, then it will not be recognized on GitHub
* if there are files that you do not want on GitHub, do a GitHub ignore directory

------

<div id='id-section2'/>  
## Page 2: 17 Jan 2018

* RSTUDIO PROJECT IS USEFUL BECAUSE YOU CAN HAVE MANY FILES WITHIN THE PROJECT AND CALL UPON DIFFERENT OBJECTS WITHOUT HAVING TO RUN ALL OF THE CODE. 
* To make a webpage, need an "index" file (saved index.rmd)
* To make a fancy webpage
  + make a repo called BMVerrico.github.io
  + download template (jekyll)
  + move to repo
  + commit, sync, etc. make changes. 
  + read the README file!

------

<div id='id-section3'/>
## Page 3: 18 Jan 2018

#### General good practices 
* Touch type: should be around 60-70words/minute
  * BMV get yo' stuff together
  
* Notebook: get a good one! 
  * Thinking on paper = key!
  
* Buy real books.
  
#### Scientific method
  * inductive method: obs- hypothesis- predictions-back to obs
    * if predictions are not met, make a new hypothesis
    * change until hypothesis encompasses original observations and updated ones
  * hypothetic deductive method (hopper's method): obs- many hypotheses (h1, h2,h3) that may account for the original observations- many predictions (p1,p2,p3)
    * the predictions and hypotheses should be as distinct as possible
    * some operational way to falsify hypothesis
    * ideally we have one hypothesis that can withstand repeated testing with evidence to support
  * statistical null hypothesis (Ho): sampling is different than null (0) 
    * p < 0.05.. probability that the data we observed given the null hypothesis (which is often noise and/or sampling error)
    * p(data|Ho)
    
#### Alternative to hypothesis testing
  * exploratory data analysis: see what the data look like
    * summaries, plots, figures
    * problem: we are freaking good at finding patterns in the data but they do not always exist!
    * pretty prevalent in big data sets (data science)
  * Parameter estimation and bayesian analysis (estimating the coefs for the models rather than testing hypotheses)
    
#### Tools to help with all of this
**1. Cause and effect diagrams**

```{}

A B : null hypothesis (no relationship)
A -> B : alt
B -> A : alt
B -> <- A : alt

Look at correlation of A and B and might see a positive linear pattern, but we cannot distinguish between the three possibilities. BECAUSE CORRELATION IS NOT ENOUGH. Need experimental data to distinguish. That is, manipulate variable one of the variables and control the other. 

#### To figure out if both A and B are acting on each other, use press and pulse experiments. 

* press- change variable and hold it constant
* pulse- change variable and then let it change

#### Could have a co-variate affecting A and B. 
Co->A->B (indirect chain) but could have Co ->B directly
Co->A but not B
Co->A and Co->B but A and B not related.

The above are mechanisms. We look at patterns in the data but we are trying to get back to the mechanism, rather than just observing the pattern. 
```

**2. Structural equation model and path analysis**
  * Examples: keystone, variable, food-web (bottom up) models
  * Do not just make one model and then use the probs on the arrows to say x,y,z. Instead, build several models and compare them. 
  
**Group literature together into hypotheses that they are testing...this seems like it would be very difficult to do!**

**3. The early graph**
  * Sketch the results if your expt/observation beforehand!
    * Deal with the problem right now rather than after a Summer of collections.
    
```{}
         |
         |
Response |   (insert bars here)
         |
          - - - - - - - - -   
            control   trt.

could have control and treatment equal (p > 0.005)
could have control higher than treatment (p < 0.005)
could have control less than treatment ( p < 0.005)

INTREPTATION AND MECHANISM! 

so, could say adding x to treatment is going to lower something. but that is just restating the hypothesis. what is the mechanism. 

Experimental manipulation should alter one and only 1 thing at a time. 

Control is not always a control, it could simply be unmanipulated.
if heating the treatment, should have the same set up just not turned on to call the other group a control

```

**4. The more interesting null hypothesis**
  * There may be sampling effects/ noise inherently in the system. 
  * Let's say you collect baseline data and have a null hypothesis of a postivie relationship. Your collected data from your experiment do not seem to have a pattern. This does not necessarily mean that there isn't a relationship, but that the relationship is just different and may be more interesting. 
  * [NG example](http://advances.sciencemag.org/content/advances/2/10/e1600842.full.pdf)
  
**5. "Dipswitch test"/ look up test**
  * Turn things on or off in the circut
  *Take results from several different experiments and combine into a single table. 
    * Each col is a different experiment
    * Each row is the results 
    * Look at all the combinations and find an interpreation of the rows 
      * Ideally there are 1 or a few rows that support the hypothesis

**6. Logic tree**
  * Series of boxes that might represent particular experiments or tests that were carried out. They represent an outcome of that expt. Simplest: yes or no.
  * Circles represent the conclusion or the stopping point of the tree. 
  * Dipswitch test can be formally mapped like this
  * Diagram/tree can help with flow of manuscript
------

<div id='id-section4'/>
## Page 4: 23 Jan 2018

* Plain text: nothing but printable text chars. that are readable by humans and machines.
  * .txt, .md (markdown format), .rmd ( R markdown format), .tex (LaTeX format)
  
* Typora: use "Command /" to toggle back and forth of how you want the text to appear and how it is "coded". Plain text view to rendered view.
  * Can go back and forth between R and Typora.
  
* Shift return for paragraph break in Slack!
* Rmarkdown uses Latex to show math (use doll hair sign)

* LaTeX editor called Overleaf is worth using when writing a manuscript and multiple people working on the document. 
  * "\title (text)"
  * Can add %% that will not render something (text, link), but useful when editing.
  * Can have different colors/author to track changes.
  
* Rmarkdown: YAML (text between the --- can be changed and it will not show)  
  * put "r" in the fence to show that it is R code, rather than markdown text.
  * do not need to add in a name to the text. can help identify what the code is, but not required to knit
  * control shift and k to knit
  
------

<div id='id-section5'/>
## Page 5: 24 Jan 2018

Working on path analyses. Used mermaid flow charts and relied heavily on the cheat sheets to do this.

------

<div id='id-section6'/>
## Page 6: 25 Jan 2018

* See FirstHTML.Rmd. Using three languages here (R, markdown, and LaTeX)

* WHEN RENDERING TO HTML THE LATEX COMMANDS ARE IGNORED. NEED TO RENDER TO PDF!

* PDF rendering only comes out one way--latex way. 

* The HTML version can have different themes, colors, fonts.

Chunk options!

* ECHO=TRUE: Execute the code and then print the code to the output.
* Eval=TRUE/FALSE: Are we going to actually run the code?
  * remember that the codes talk to each other. if you do not evaluate a chunk of code with objects called, then you cannot call upon them later unless you define them elsewhere. same is true for packages loaded into R.
* Message=FALSE: Do not show any messages printed to screen after running the code.

* We are using the .rmd but under the hood the itermediate file we are actually working with is .md. This file can then be changed to .html, .pdf, .doc. If you go to settings, you can hold on to the .md file. This is not always kept. 

* .css file is cascading style sheet. can use those from typora to format rmarkdown files.

------

<div id='id-section7'/>
## Page 7 30 Jan 2018

**Beamer Baby!!**

* Rmarkdown-presentation-choose format
* "##" means a new slide.
* Render bullet something incrementally --check in the settings!
  * good to put bullet points in one at a time. because audience will read everything all at once. adding the bullets in one at a time will force the readers to read the text as you talk about it.
* Can comment in the beamer slides without it showing on the pdf when rendered. do this with LaTeX code ($ or %)
* Need to have all images saved in the directory of the .rmd.

```{}
         typora
           |
.rmd -> (.md) - can make .html, .pdf (based on .md), .pdf (beamer slides)

.Rnw (sweave) --------- .pdf (LaTeX)
```

To change the .rmd to .r (regular script) in the console.

```{}
library(knitr)
purl("FirstHTML.Rmd")
```

To change old R script code to an HTML or PDF without the .rmd file, use the notebook button. 

```{}
 .R --------------------(with notebook)    
  |  (with purl)            |     |
.rmd -> (.md) - can make .html, .pdf (based on .md), .pdf (beamer slides)
```


**To R scripts we go!**

* History and the up arrow in the console shows previous code.
* Try to break the = habit and use <- instead...you can do this BMV!
```{}
control l: clear the consol
control enter: run line(s) of code
control shift enter: run everything in the script
```

**Data types**

Homogeneous: same type of data, hetero=opposite

I need to learn how to make tables!

Dimensions  Homogeneous  Heterogeneous
1           Atomic vector   List
2           Matrix        Data frame (kind of list)
n           Array

* Character string "i" (green font)
* Integers (numeric)
* Doubles (doubles precision) (numeric)
* logical (TRUE T, FALSE F) (bright pink font)
* factor (set of character strings, groups, used in statistical models)

------

<div id='id-section8'/>
## Page 8 31 Jan 2018

Made beamer presentation using notes above and from class webpage.

------

<div id='id-section9'/>
## Page 9 01 Feb 2018

Useful commands that you have used before but good to remember

1. typeof() --- TYPE OF OBJECT
2. str() --- STRUCTURE
3. is.____ (e.g. numeric)()---EVALUATE
4. names(vector object)

* Scaler is a single numeric vector (length of 1)
* Remember to enter NA for missing data into the datasheet or wherever data is being stored. This is good practice to make it easier when loading data into R. 
* NaN (not a number)
* hierarchy of conversion
  * logicals -> integers -> double -> character

------

<div id='id-section10'/>  
## Page 10: 06 Feb 2018

All notes are in BasicCoding.R

------

<div id='id-section11'/>  
## Page 11: 07 Feb 2018

All notes are in BasicCoding.R and MatricesLists.R.

------

<div id='id-section12'/>  
## Page 12: 08 Feb 2018

All notes are in BasicCoding.R and MatricesLists.R.

------

<div id='id-section13'/>  
## Page 13: 13 Feb 2018

**Regular expressions!!**

* Grep: special case of searching regular expression. 
* Cleaning data is different than data wrangling
  * copy dataset! no track changes unless commands are written otherwise
  * wrangling is more formatting the data
* If using basic text editor, uncheck 'grep' to search for the literal character. If you include 'grep', escape the metacharacter with a slash \
* Commands are generally greedy unless otherwise specified
* black: reg expression, blue: wildcard red: quantifiers 
* `\\` search for the `\`  

Wilcards

1. `.` any character or space other than an end-of-line 
2. `\w` a single word character ( letter, number, or _)
3. `\d` a single number character [0-9]
4. `\t` a single tab space
5. `\s` a single space, tab, or line break
6. `\n` a single line break

Quantifyers

1. `\w +` one or more consecutive word characters
2. `\w*` zero or more consecutive word characters
3. `\w{3,}` find 3 or more consecutive word characters
4. `\3{3,5}` find 3,4, or 5 consecutive word characters 

* `.csv` normally there is a single space between the comma and the character string.
  * if there are zero or 1+ spaces--need to clean this
  `\s*,\s*/, /` 
  find one or more spaces followed by a comma, followed by one or more spaces, replace with a comma and a space

Example: find each line
```{}
x, MyWord OtherJunk. ,
13, MyWord2,OtherStuff,,
X13, MyThirdWord,	More trash|##
xxx,LastWord	x.

\w+,\s*\w+.*
Look for characters (at least 1) and stop at the comma (search for the comma too). Then search for another word without looking for any space. It is greedy so it will make the word as long as it can until it hits a non-word character. In this case, a comma, space, or period. The asterisk here says keep everything else that is on the line out to the line break. 
```

Steps to do with reg. expressions

1. Find the different elements in the text
2. Capture some of the elements
3. Replace some of the elements

* Use `()` to capture text. 
* Specify consecutive capture elements with `\1` `\2` etc in the replacement string
* can mix capture text with literal text

Example: capture
```{}
x, MyWord OtherJunk. ,
13, MyWord2,OtherStuff,,
X13, MyThirdWord,	More trash|##
xxx,LastWord	x.

Find: \w+,\s*(\w+).*
Replace: ImportantStuff: \1

ImportantStuff: MyWord
ImportantStuff: MyWord2
ImportantStuff: MyThirdWord
ImportantStuff: LastWord
```

Example with multiple searches from above
```{}
(\w+),\s*(\w+).*
  \2, \1
  
MyWord, x
MyWord2, 13
MyThirdWord, X13
LastWord, xxx
```

Genus and species names
```{}
Lasius neoniger
Lasius umbratus
Myrmica lobifrons

Find: \w\w+\s\w+
Capture: (\w)\w+\s(\w+)
Replace: \1_\2

L_neoniger
L_umbratus
M_lobifrons

In words: Find first letter of the genus and then find the rest of the genus name. Search for single space. Being lazy and assuming that there is only one space between genus and species. Then find the entire species name. Capture the first letter of the genus and the entire name of the species. Replace with First letter of genus _ species.

L_neoniger
L_umbratus
M_lobifrons

Find: (\w)\_(\w+)
Replace: \1, \2

L, neoniger
L, umbratus
M, lobifrons
```

Create custom character sets
  * Characters (, and ^) are needed but ignored
  * No real order here
  * Use brackets when we are not sure what we are exactly looking for.
  * Use regular searches as above if something is specific
  
1. `\[A,C,T,G]` finds a single nucleotide 
2. `\[A,C,T,G]+` finds a sequence of nucleotides 
3. `[^A,C,T,G]+` find a string that is not a sequence
4. `\[A,C,T,G]{20}` finds a sequence that is 20 in length

R package called `stringr` can help deal with character strings. Similar to regregular expressions. More helpful if data is continuously added to the dataset. The reg. expressions are like a one and done thing. Can have a script in R to record what is done though. 

------

<div id='id-section14'/>  
## Page 14: 14 Feb 2018

Worked with regular expressions to complete homework 5. No new notes.

------

<div id='id-section15'/>  
## Page 15: 15 Feb 2018

ignore typos... typing quickly to catch up.

**Working with probability distributions.** 

* Deterministic model: get same answer every time model is used. analytical. mathematical.
* Stochastic model: do not get same answer every time because there is a variable, or multiple variables that change in the model. 

* Randomness= ignorance. 

In reality, there is no uncertainty because there is a chain of cause and effect events that lead to the current situation. We just do not know what the story is with all of the steps. We lump this ignorance and uncertainty into the randomness. Equates to one variable in the model. 

**Notes about mean and variance.**

* will need to look at paper to get the equations. 
* remember that variance is the variability of each obs around the mean. 
* the function is squared so that the variance is always positive, or 0 if every obs is equal to the mean.

**Moments**

1. mean
2. variance
3. skewness: how much do the data skew to the left or the right (non-symmetrical)
4. kurtosis: shape of the distribution with regards to the tails. skinny or fat tails of the distribution

**Rstudio: rnorm, dnorm, pnorm, qnorm**

* qnorm is the inverse of pnorm (looks at quantiles, like between 5 and 95%)
* pnorm involves the cumulative area function (0-1)
* dnorm looks at the count of observations. area under the curve =1
  * remember that x is continuos, so mass above any particular point is 0, but when x is binned we can see that some values of x have > mass than others
  
**Functions**

See notes in probDist.R

------

<div id='id-section16'/>  
## Page 16: 20 Feb 2018

See notes in probDist.R

* statistical p = p(data | hypothesis)
  * how probable are the data if this hypothesis is true

* what is the probability of the data given the model parms that are present
  * p = p(data | parms)
  
* what is the probability of these parms given the data
(how likely are the parms)
  * p= (parms | data)
  * for the data that you have the combination of parms is the most probable or most likely. 
  * max like= max(p(parms | data))
  
* there are more likely values or most likely values for a given parm, and these are called the maximum likelihood value 

------

<div id='id-section17'/>  
## Page 17: 22 Feb 2018

1. Begin with an observed data set. Something we already collected.
    * Data follows some sort of distribution which can be seen with histogram
    
2. Choose appropriate statistical distribution.
    * bounded vs. unbounded
    * discrete vs continuous
    
3. Each distribution has its own shape and parms (e.g. mean, sd)
    * When parms are changed, the distribution shape is changed. 
    * Want to choose the best parms that fit our data the best
    * Use f(x) `fitdistr` to get maximum likelihood estimates of the model parms. This says, this is the combo of parms that characterizes the curve that best fits the data.
    
4. Get mean and variance of the data. 
     * We get these for any distribution fit we make. 
     * Parms in the model generate a mean and variance for a simulated dataset
     
5. What would means and variances look like for different groups in our experiment?
     * What do we expect to find? What should the pattern of parms look like between the groups if the hypothesis is true?
     
6. Change the values of the parms and simulate a data set.
    * We will need a different set of parms for each group in the experiment. 
    * Set up the idealized world. 
    * Are the simulated data reasonable?
7. Compare groups in the fake data set with ANOVA, regression, etc.

8. P value is determined by the sample size (n), within group variance, differences in means of different groups (effect size)= LOOK AT THESE!
    * for each group, should have at least 10 obs. (rule of 10 ind. replicates-- measurement on one unit does not affect or relie on other units)
    * sample size is largely determined by logistics (time, money, space)
    * what is the maximum total n possible? is the sample size actually large enough to find the effect that is there.
    * within group variance: heterogenity in the histogram.
      * still want some variance within the group (e.g. genos-biological)
        * but do not want statistical error. (range of var--larger it is, the more difficult it will be to see the pattern)
      * among group means- depends on the preds of the hypothesis but also on what the reasonable values are. likely an upper and lower limt, but the means themselves should be different (depending on the hypothesis)
      
9. Analyze the model with the fake data- generate a p-value
    * if p >0.05 (not sig.) how much replication needed to get a sig result
        * crank up the sample size. experimental design change.
    * if p >0.05 how large would the differences in the group means need to be to get sig result
        * here do not change the sample size, but how far apart do means need to be? effect size! shift mean value of 1 or more of the group. not changing the experimental conditions but rather the response. tinker with the parms that generate the parms. when means are shifted then you need to ask if the means are actually biologically feasible. 
    * can ask the reverse questions if p < 0.05. how far can i decrease sample size, how small can the mean value differences be?
        

**Metadata: description of EVERYTHING in the dataset.**

**This should live with the actual data. same file. this is amazing.**

ID: sequential row count! row names =1, header = TRUE

```{}
data=read.table(file="Filename.csv", row.names = 1, header=TRUE, sep=",",
                stringsAsFactors = FALSE)
               # Call factors later on. 
```

------

<div id='id-section'/>  
## Page 18: 27 Feb 2018

* Variable: dependent or independent
* Discrete or continuous (integer, real number)

* Independent and dependent vars can discrete or continuous

* 2 continuous vars= regression
* Indepdent=discrete, dependent=continuous = anova
* Indepdent=continuous, dependent=discrete = logisitic regression (0,1 response for x axis)
* 2 discrete vars= contingency analysis

What to do:
* Look to see how the data need to be structured. I.e. how does the data frame need to look.
* Model code
* Simple visualization


Regression: 
* a and b do they differ from 0-hypothesis testing
* line drawn: mle to see best fit
* null hypothesis is that the data are scattered 
* r squared: how much variation is explained. 
* 1= all variance explained, 0= no variance explained, model has no predictor power

Continuous: measurements (length, temperature, ppt)
Discrete: categorical (count data

ANOVA: differences between the groups
Regression: is there a relationship between x and y

------

<div id='id-section'/>  
## Page 19: 1 Mar 2018

Everything in exptdesign.R and functions.R

Anatomy of uses: defined R functions

```
function name= function (parm X =some number of function assigned to X[default X], parm y= something, parm Z= something) {

lines of R code and annotations
may call other functions
may create new functions
may create local variables

return(z--could be a list or a vector))
}
```
function name  # prints contents of the function
function name () # calls function with default values
function name (parm X=10, parm Y=FALSE, parm Z=c(2,3,4))


Style for functions

* fence off funcion with prominent comments
* give header and description of the function, input, output
* simple names for local vars
* no more than ~1 screenful of code-- chunk of the functions
* provide default values for all parms
* use random number generator to create the default values
    * each time you run the default you get a different set of values
        * rather than manually change the numbers
        
